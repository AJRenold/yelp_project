{
 "metadata": {
  "name": "Ensemble_test"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "from itertools import islice\n",
      "from collections import Counter, defaultdict\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import re\n",
      "import nltk\n",
      "\n",
      "# sklean\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "# our bayes\n",
      "from bayes import NaiveBayes\n",
      "\n",
      "# news group data\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "\n",
      "print os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/ajrenold/Dropbox/iSchool/2013Spring/DataMining/yelp_project\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dict = {}\n",
      "file_dict['reviews'] = 'yelp_academic_dataset_review.json'\n",
      "file_dict['stopwords'] = 'stop-words-english3-google.txt'\n",
      "file_dict['business'] = 'yelp_academic_dataset_business.json'\n",
      "file_dict['users'] = 'yelp_academic_dataset_user.json'\n",
      "\n",
      "review_file = open(file_dict['reviews'])\n",
      "review_file_s = islice(review_file,None)\n",
      "print file_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'reviews': 'yelp_academic_dataset_review.json', 'stopwords': 'stop-words-english3-google.txt', 'users': 'yelp_academic_dataset_user.json', 'business': 'yelp_academic_dataset_business.json'}\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('stop_names.csv')\n",
      "print f\n",
      "\n",
      "stop_names = {}\n",
      "\n",
      "for line in islice(f,None):\n",
      "    word = line.lower().strip()[line.find(',')+1:]\n",
      "    if word not in stop_names:\n",
      "        stop_names[word] = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<open file 'stop_names.csv', mode 'r' at 0x12c09adb0>\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_json = open(file_dict['reviews'])\n",
      "reviews_for_df = [ json.loads(line) for line in review_json ]\n",
      "review_df = pd.DataFrame(reviews_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_json = open(file_dict['users'])\n",
      "user_for_df = [ json.loads(line) for line in user_json ]\n",
      "user_df = pd.DataFrame(user_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create avg_useful_votes in users_df\n",
      "user_df = user_df.set_index(['user_id'])\n",
      "user_df['useful_votes'] = user_df['votes'].apply(lambda x: x['useful'])\n",
      "user_df['avg_useful_votes'] = user_df.apply(lambda series: float(series['useful_votes'])/float(series['review_count']),axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "business_json = open(file_dict['business'])\n",
      "business_json_list = [ json.loads(line) for line in islice(business_json,None) ]\n",
      "\n",
      "business_dict = {}\n",
      "for biz in business_json_list:\n",
      "    business_dict[biz['business_id']] = biz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 229907 entries, 0 to 229906\n",
        "Data columns:\n",
        "business_id    229907  non-null values\n",
        "date           229907  non-null values\n",
        "review_id      229907  non-null values\n",
        "stars          229907  non-null values\n",
        "text           229907  non-null values\n",
        "type           229907  non-null values\n",
        "user_id        229907  non-null values\n",
        "votes          229907  non-null values\n",
        "dtypes: int64(1), object(7)"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenize_avg_useful_votes(votes):\n",
      "    if votes == 0:\n",
      "        return \"userAvg0\"*2\n",
      "    elif votes <= 0.5:\n",
      "        return \"userAvgPoint5\"\n",
      "    elif votes <= 1:\n",
      "        return \"userAvg1\"\n",
      "    elif votes <= 1.5:\n",
      "        return \"userAvg1Point5\"\n",
      "    elif votes <= 2:\n",
      "        return \"userAvg2\"\n",
      "    elif votes <= 2.5:\n",
      "        return \"userAvg2Point5\"*2\n",
      "    else:\n",
      "        return \"userAvgHigh\"*2\n",
      "    \n",
      "def append_user_token(series):\n",
      "    try:\n",
      "        return series['text'] + ' ' + user_df.ix[series['user_id']]['useful_token']\n",
      "    except:\n",
      "        return series['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_df['useful_token'] = user_df['avg_useful_votes'].apply(tokenize_avg_useful_votes)\n",
      "review_df['text'] = review_df.apply(append_user_token, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract useful_votes from votes column\n",
      "\n",
      "#review_df['tokens'] = review_df['text'].apply(nltk.word_tokenize) # tokenize using nltk\n",
      "review_df['useful_votes'] = review_df['votes'].apply(lambda x:x['useful']) # extract useful votes\n",
      "review_df = review_df.set_index(['review_id']) # index on review_id\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# partition data to train and test\n",
      "\n",
      "train = []\n",
      "test = []\n",
      "for row in islice(review_df[['text','useful_votes','business_id']].iterrows(),None):\n",
      "    if 'Restaurants' in business_dict[row[1]['business_id']]['categories']:\n",
      "        train_or_test = np.random.uniform()\n",
      "        # partition training data\n",
      "        if train_or_test < 0.8:\n",
      "            train.append(row[1])\n",
      "        # partition testing data\n",
      "        else:\n",
      "            test.append(row[1])\n",
      "        \n",
      "train_df = pd.DataFrame(train)\n",
      "test_df = pd.DataFrame(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 126410 entries, IjZ33sJrzXqU-0X6U8NwyA to z5b2p5TbCg0uaIiIe8n62w\n",
        "Data columns:\n",
        "text            126410  non-null values\n",
        "useful_votes    126410  non-null values\n",
        "business_id     126410  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 32020 entries, fWKvX83p0-ka4JS3dc6E5A to f9JaiNg_FMoPNWxt7MlbZQ\n",
        "Data columns:\n",
        "text            32020  non-null values\n",
        "useful_votes    32020  non-null values\n",
        "business_id     32020  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get reviews with useful votes from training data\n",
      "useful_review_df = train_df[train_df['useful_votes']>1] # 40 percent votes are 0 , 28 % are 1 , discarding those\n",
      "useful_review_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 36996 entries, m2CKSsepBCoRYWxiRUsxAg to z5b2p5TbCg0uaIiIe8n62w\n",
        "Data columns:\n",
        "text            36996  non-null values\n",
        "useful_votes    36996  non-null values\n",
        "business_id     36996  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create labels for NaiveBayes\n",
      "train_labels = []\n",
      "train_text = []\n",
      "for row in train_df.iterrows():\n",
      "    if row[1]['useful_votes'] == 0:\n",
      "        train_labels.append('0')\n",
      "        train_text.append(row[1]['text'])\n",
      "    elif row[1]['useful_votes'] >= 2:\n",
      "        train_labels.append('1')\n",
      "        train_text.append(row[1]['text'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train NaiveBayes\n",
      "% time clfr = NaiveBayes(train_text, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'1': 0.41375608119443047, '0': 0.5862439188055696}\n",
        "4332"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 26.81 s, sys: 0.70 s, total: 27.50 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 27.36 s\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_features = clfr.max_entropy(1500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_exclude = ['NNP','NNPS','PRP','PRP$','WRB','CC','IN']\n",
      "feature_words = [ f[1] for f in max_features ]\n",
      "tagged_feature_words = nltk.pos_tag(feature_words)\n",
      "features = [ word[0] for word in tagged_feature_words if word[1] not in pos_exclude and word[0] not in stop_names ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(features)\n",
      "print features[0:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1460\n",
        "[u'lobbys', u'gabi', u'useravghighuseravghigh', u'www', u'fez', u'http', u'pics', u'palatte', u'christophers', u'drift', u'fucking', u'mrs', u'cenpho', u'dusted', u'aforementioned', u'caf\\xe9', u'joined', u'yelping', u'spicey', u'shitty', u'fuck', u'pic', u'gritty', u'polished', u'uh', u'wiseguy', u'yelper', u'patiently', u'condesa', u'garnished', u'profile', u'ms', u'insert', u'definately', u'stared', u'mr', u'blech', u'sweetened', u'marketing', u'maizies', u'beignets', u'pancetta', u'bitch', u'sending', u'determined', u'knowledgable', u'navajo', u'butterfields', u'amuse', u'2008', u'strangers', u'als', u'shit', u'brio', u'sex', u'prove', u'glorious', u'dillys', u'gladly', u'oranges', u'license', u'manchego', u'quiessence', u'wildfish', u'mabels', u'disappoints', u'durants', u'british', u'cantonese', u'accents', u'thyme', u'throat', u'shiny', u'lolos', u'bomberos', u'biancos', u'beloved', u'lap', u'contrast', u'begins', u'com', u'creating', u'picazzos', u'laughed', u'fifth', u'twitter', u'remembers', u'favs', u'capacity', u'heres', u'failure', u'pomegranate', u'canyon', u'bjs', u'rocket', u'substance', u'naked', u'mamma', u'ugly', u'newest']\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Re-write to optimize time\n",
      "#### NOT YET FINISHED\n",
      "\n",
      "def get_review_len_token(review_len):\n",
      "    if review_len <= 100:\n",
      "        return 'review_len_100'\n",
      "    elif review_len <= 200:\n",
      "        return 'review_len_200'\n",
      "    elif review_len <= 300:\n",
      "        return 'review_len_300'\n",
      "    elif review_len <= 400:\n",
      "        return 'review_len_400'\n",
      "    elif review_len <= 500:\n",
      "        return 'review_len_500'\n",
      "    elif review_len <= 600:\n",
      "        return 'review_len_600'\n",
      "    elif review_len <= 700:\n",
      "        return 'review_len_700'\n",
      "    elif review_len <= 800:\n",
      "        return 'review_len_800'\n",
      "    elif review_len <= 900:\n",
      "        return 'review_len_900'\n",
      "    elif review_len <= 1000:\n",
      "        return 'review_len_1000'\n",
      "    else:\n",
      "        return 'review_len_long'\n",
      "\n",
      "def tokenize(text):\n",
      "    text = re.sub(r\"[\\n\\.,;\\!\\?\\(\\)\\[\\]\\*/:+\\-\\~]\",\" \",text.lower())\n",
      "    text = re.sub(r\"(\\b[\\d]+\\b|\\b[\\d]+[a-z]+\\b)\",\" \",text)\n",
      "    #inplist = nltk.word_tokenize(text)    \n",
      "    inplist = text.split(' ')\n",
      "    finallist = list()\n",
      "    result = list()\n",
      "    # wordcorrect for tokens\n",
      "    #finallist = wordcorrect(inplist)\n",
      "    finallist = inplist\n",
      "    \n",
      "    finallist.append(get_review_len_token(len(inplist)))\n",
      "    \n",
      "    for i in range(len(finallist)):        \n",
      "        #if stops.has_key(inplist[i]): # remove stop words\n",
      "        #   continue\n",
      "        if '$' in inplist[i]:\n",
      "            result.append('priceMention')\n",
      "        else:\n",
      "            result.append(inplist[i])\n",
      "    \n",
      "    return result\n",
      "\n",
      "def create_training_input(text,feature_words):\n",
      "    #extracted_features = tfidf_vectorize(text)\n",
      "    count_vect = CountVectorizer(tokenizer = tokenize,vocabulary = feature_words, min_df=30)\n",
      "    return count_vect, count_vect.fit_transform(text)\n",
      "\n",
      "%time count_vect, training_input = create_training_input(useful_review_df['text'][:],features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 12.15 s, sys: 0.11 s, total: 12.26 s\n",
        "Wall time: 12.20 s\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train LRModel\n",
      "trnglabels = useful_review_df['useful_votes'][:]\n",
      "LRModel = LinearRegression()\n",
      "%time LRModel.fit(training_input,trnglabels)\n",
      "modelpar = LRModel.coef_\n",
      "print min(modelpar),max(modelpar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0.89 s, sys: 0.01 s, total: 0.90 s\n",
        "Wall time: 0.90 s\n",
        "-4.29037343299 9.02042934333\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test LRModel on its own\n",
      "testrange = count_vect.fit_transform(test_df['text'][:])\n",
      "pred_results = LRModel.predict(testrange.toarray())\n",
      "res = zip(test_df['useful_votes'][:].values,pred_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LRModel RMSE\n",
      "errors = []\n",
      "for r in res:\n",
      "    err = abs(r[0]-r[1])\n",
      "    errors.append(err)\n",
      "    \n",
      "print np.sqrt(np.mean([ e**2 for e in errors ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.91990255354\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = defaultdict(Counter)\n",
      "results = []\n",
      "\n",
      "for i,item in enumerate(test_df['text']):\n",
      "    label = clfr.label_new(item)\n",
      "    if label[0][1] == '1':\n",
      "        testrange = count_vect.fit_transform([item])\n",
      "        votes = LRModel.predict(testrange.toarray())\n",
      "        results.append((votes[0],test_df['useful_votes'][i]))\n",
      "        #results.append((1.5,test_df['useful_votes'][i]))\n",
      "    #elif label[0][1] == '2':\n",
      "    #    results.append((4.5,test_df['useful_votes'][i]))\n",
      "    #elif label[0][1] == '3' or label[0][1] == '2':\n",
      "    #    testrange = count_vect.fit_transform([item])\n",
      "    #    votes = LRModel.predict(testrange.toarray())\n",
      "    #    results.append((votes[0],test_df['useful_votes'][i]))\n",
      "    else:\n",
      "        results.append((0,test_df['useful_votes'][i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_df['text'][5], results[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "(u\"I love this place! I have been coming here for ages.\\nMy favorites: Elsa's Chicken sandwich, any of their burgers, dragon chicken wings, china's little chicken sandwich, and the hot pepper chicken sandwich. The atmosphere is always fun and the art they display is very abstract but totally cool! userAvg1\",\n",
        " (0, 1))"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Labeling RMSE\n",
      "# >= 4 is 2.72\n",
      "#\n",
      "# >= 2 is 2.69\n",
      "\n",
      "errors = []\n",
      "for r in results:\n",
      "    err = abs(r[0]-r[1])\n",
      "    errors.append(err)\n",
      "\n",
      "print np.sqrt(np.mean([ e**2 for e in errors ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.303508553\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    }
   ],
   "metadata": {}
  }
 ]
}