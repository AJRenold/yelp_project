{
 "metadata": {
  "name": "Ensemble_test"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "from itertools import islice\n",
      "from collections import Counter, defaultdict\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import re\n",
      "import nltk\n",
      "\n",
      "# sklean\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "# our bayes\n",
      "from bayes import NaiveBayes\n",
      "\n",
      "# news group data\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "\n",
      "print os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/ajrenold/Dropbox/iSchool/2013Spring/DataMining/yelp_project\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dict = {}\n",
      "file_dict['reviews'] = 'yelp_academic_dataset_review.json'\n",
      "file_dict['stopwords'] = 'stop-words-english3-google.txt'\n",
      "file_dict['business'] = 'yelp_academic_dataset_business.json'\n",
      "\n",
      "review_file = open(file_dict['reviews'])\n",
      "review_file_s = islice(review_file,None)\n",
      "print file_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'reviews': 'yelp_academic_dataset_review.json', 'stopwords': 'stop-words-english3-google.txt', 'business': 'yelp_academic_dataset_business.json'}\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(file_dict['stopwords'])\n",
      "print f\n",
      "\n",
      "stops = {}\n",
      "\n",
      "for line in islice(f,None):\n",
      "    word = line.lower().strip()\n",
      "    if word not in stops:\n",
      "        stops[word] = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<open file 'stop-words-english3-google.txt', mode 'r' at 0x104e8a390>\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_json = open(file_dict['reviews'])\n",
      "reviews_for_df = [ json.loads(line) for line in review_file_s ]\n",
      "review_df = pd.DataFrame(reviews_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "business_json = open(file_dict['business'])\n",
      "business_json_list = [ json.loads(line) for line in islice(business_json,None) ]\n",
      "\n",
      "business_dict = {}\n",
      "for biz in business_json_list:\n",
      "    business_dict[biz['business_id']] = biz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 229907 entries, 0 to 229906\n",
        "Data columns:\n",
        "business_id    229907  non-null values\n",
        "date           229907  non-null values\n",
        "review_id      229907  non-null values\n",
        "stars          229907  non-null values\n",
        "text           229907  non-null values\n",
        "type           229907  non-null values\n",
        "user_id        229907  non-null values\n",
        "votes          229907  non-null values\n",
        "dtypes: int64(1), object(7)"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract useful_votes from votes column\n",
      "\n",
      "#review_df['tokens'] = review_df['text'].apply(nltk.word_tokenize) # tokenize using nltk\n",
      "review_df['useful_votes'] = review_df['votes'].apply(lambda x:x['useful']) # extract useful votes\n",
      "review_df = review_df.set_index(['review_id']) # index on review_id\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# partition data to train and test\n",
      "\n",
      "train = []\n",
      "test = []\n",
      "for row in islice(review_df[['text','useful_votes','business_id']].iterrows(),None):\n",
      "    if 'Restaurants' in business_dict[row[1]['business_id']]['categories']:\n",
      "        train_or_test = np.random.uniform()\n",
      "        # partition training data\n",
      "        if train_or_test < 0.8:\n",
      "            train.append(row[1])\n",
      "        # partition testing data\n",
      "        else:\n",
      "            test.append(row[1])\n",
      "        \n",
      "train_df = pd.DataFrame(train)\n",
      "test_df = pd.DataFrame(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 126692 entries, fWKvX83p0-ka4JS3dc6E5A to z5b2p5TbCg0uaIiIe8n62w\n",
        "Data columns:\n",
        "text            126692  non-null values\n",
        "useful_votes    126692  non-null values\n",
        "business_id     126692  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 31738 entries, IjZ33sJrzXqU-0X6U8NwyA to TzRaZKK9jWLOJ34RUkwS2Q\n",
        "Data columns:\n",
        "text            31738  non-null values\n",
        "useful_votes    31738  non-null values\n",
        "business_id     31738  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get reviews with useful votes from training data\n",
      "useful_review_df = train_df[train_df['useful_votes']>1] # 40 percent votes are 0 , 28 % are 1 , discarding those\n",
      "useful_review_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 37107 entries, fWKvX83p0-ka4JS3dc6E5A to z5b2p5TbCg0uaIiIe8n62w\n",
        "Data columns:\n",
        "text            37107  non-null values\n",
        "useful_votes    37107  non-null values\n",
        "business_id     37107  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create labels for NaiveBayes\n",
      "train_labels = []\n",
      "train_text = []\n",
      "for row in train_df.iterrows():\n",
      "    if row[1]['useful_votes'] == 0:\n",
      "        train_labels.append('0')\n",
      "        train_text.append(row[1]['text'])\n",
      "    elif row[1]['useful_votes'] >= 2:\n",
      "        train_labels.append('1')\n",
      "        train_text.append(row[1]['text'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train NaiveBayes\n",
      "% time clfr = NaiveBayes(train_text, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'1': 0.41400200825616423, '0': 0.5859979917438358}\n",
        "5185"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 32.90 s, sys: 0.81 s, total: 33.72 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 33.90 s\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_features = clfr.max_entropy(2000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_exclude = ['NNP','NNPS','PRP','PRP$','WRB','CC','IN']\n",
      "feature_words = [ f[1] for f in max_features ]\n",
      "tagged_feature_words = nltk.pos_tag(feature_words)\n",
      "features = [ word[0] for word in tagged_feature_words if word[1] not in pos_exclude ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_feature_words[0:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "[(u'carin', 'NN'),\n",
        " (u'biz_photos', 'NNP'),\n",
        " (u'rand', 'NN'),\n",
        " (u'lobbys', 'NNS'),\n",
        " (u'gabi', 'VBP'),\n",
        " (u'jared', 'VBN'),\n",
        " (u'fez', 'NN'),\n",
        " (u'www', 'NN'),\n",
        " (u'http', 'NN'),\n",
        " (u'fucking', 'VBG'),\n",
        " ('review_len_1000', 'NNP'),\n",
        " ('review_len_long', 'NNP'),\n",
        " ('review_len_100', 'NNP'),\n",
        " (u'lumpia', 'NN'),\n",
        " ('review_len_800', 'NNP'),\n",
        " (u'pics', 'NNS'),\n",
        " (u'drift', 'VBP'),\n",
        " ('review_len_900', 'NNP'),\n",
        " (u'lisa', 'NN'),\n",
        " ('review_len_700', 'NNP'),\n",
        " (u'als', 'NNS'),\n",
        " (u'cenpho', 'WP'),\n",
        " (u'bomberos', 'NNS'),\n",
        " (u'h', 'VBP'),\n",
        " (u'fate', 'JJ'),\n",
        " (u'gay', 'NN'),\n",
        " (u'yelper', 'NN'),\n",
        " (u'sink', 'NN'),\n",
        " (u'mrs', 'NNS'),\n",
        " (u'uh', 'VBP'),\n",
        " (u'durants', 'NNS'),\n",
        " (u'knowledgable', 'JJ'),\n",
        " (u'matt', 'NN'),\n",
        " (u'shitty', 'NN'),\n",
        " (u'pate', 'NN'),\n",
        " (u'definately', 'RB'),\n",
        " (u'contrast', 'JJ'),\n",
        " (u'pancetta', 'NN'),\n",
        " (u'amuse', 'NN'),\n",
        " (u'cured', 'VBD'),\n",
        " (u'pic', 'JJ'),\n",
        " (u'license', 'NN'),\n",
        " (u'caf\\xe9', 'NN'),\n",
        " (u'glorious', 'JJ'),\n",
        " (u'fuck', 'NN'),\n",
        " (u'roosevelt', 'NN'),\n",
        " (u'monkey', 'NN'),\n",
        " (u'thomas', 'NNS'),\n",
        " (u'shit', 'VBP'),\n",
        " (u'polished', 'VBN'),\n",
        " (u'laughed', 'VBN'),\n",
        " ('review_len_600', 'NNP'),\n",
        " (u'atop', 'NN'),\n",
        " (u'prove', 'VBP'),\n",
        " (u'aforementioned', 'VBN'),\n",
        " (u'lolos', 'NNS'),\n",
        " (u'pricy', 'NN'),\n",
        " (u'edit', 'NN'),\n",
        " (u'beauty', 'NN'),\n",
        " (u'bitch', 'NN'),\n",
        " (u'matts', 'NNS'),\n",
        " (u'stella', 'NN'),\n",
        " (u'choy', 'NN'),\n",
        " (u'hippies', 'NNS'),\n",
        " (u'umm', 'VBP'),\n",
        " (u'marketing', 'VBG'),\n",
        " (u'flash', 'NN'),\n",
        " (u'colored', 'VBD'),\n",
        " (u'g', 'NN'),\n",
        " (u'blanco', 'NN'),\n",
        " (u'carlys', 'NNS'),\n",
        " (u'ycs', 'NNS'),\n",
        " (u'joined', 'VBD'),\n",
        " (u'com', 'NN'),\n",
        " (u'tuck', 'NN'),\n",
        " (u'mike', 'NN'),\n",
        " (u'mr', 'NN'),\n",
        " (u'beloved', 'VBD'),\n",
        " (u'akor', 'NN'),\n",
        " (u'wondered', 'VBN'),\n",
        " ('review_len_500', 'NNP'),\n",
        " (u'james', 'VBZ'),\n",
        " (u'gladly', 'RB'),\n",
        " (u'sens', 'VBZ'),\n",
        " (u'numbers', 'NNS'),\n",
        " (u'yucca', 'VBP'),\n",
        " (u'wind', 'JJ'),\n",
        " (u'petite', 'NN'),\n",
        " (u'chilled', 'VBD'),\n",
        " (u'stared', 'VBN'),\n",
        " (u'slab', 'NN'),\n",
        " (u'magical', 'JJ'),\n",
        " (u'dropout', 'NN'),\n",
        " (u'india', 'NNS'),\n",
        " (u'feast', 'VBP'),\n",
        " (u'pee', 'NN'),\n",
        " (u'oranges', 'NNS'),\n",
        " (u'delights', 'NNS'),\n",
        " (u'stylish', 'VBP'),\n",
        " (u'confirmed', 'VBN')]"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Re-write to optimize time\n",
      "#### NOT YET FINISHED\n",
      "\n",
      "def tokenize(text):\n",
      "    text = re.sub(r\"[\\n\\.,;\\!\\?\\(\\)\\[\\]\\*/:+\\-\\~]\",\" \",text.lower())\n",
      "    text = re.sub(r\"(\\b[\\d]+\\b|\\b[\\d]+[a-z]+\\b)\",\" \",text)\n",
      "    #inplist = nltk.word_tokenize(text)    \n",
      "    inplist = text.split(' ')\n",
      "    finallist = list()\n",
      "    result = list()\n",
      "    # wordcorrect for tokens\n",
      "    #finallist = wordcorrect(inplist)\n",
      "    finallist = inplist\n",
      "    \n",
      "    for i in range(len(finallist)):        \n",
      "        if stops.has_key(inplist[i]): # remove stop words\n",
      "            continue\n",
      "        elif '$' in inplist[i]:\n",
      "            result.append('priceMention')\n",
      "        else:\n",
      "            result.append(inplist[i])\n",
      "    \n",
      "    return result\n",
      "\n",
      "def create_training_input(text,feature_words):\n",
      "    #extracted_features = tfidf_vectorize(text)\n",
      "    count_vect = CountVectorizer(tokenizer = tokenize,vocabulary = feature_words, min_df=30)\n",
      "    return count_vect, count_vect.fit_transform(text)\n",
      "\n",
      "%time count_vect, training_input = create_training_input(useful_review_df['text'][:],features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 12.66 s, sys: 0.13 s, total: 12.80 s\n",
        "Wall time: 12.73 s\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train LRModel\n",
      "trnglabels = useful_review_df['useful_votes'][:]\n",
      "LRModel = LinearRegression()\n",
      "%time LRModel.fit(training_input,trnglabels)\n",
      "modelpar = LRModel.coef_\n",
      "print min(modelpar),max(modelpar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.90 s, sys: 0.01 s, total: 1.91 s\n",
        "Wall time: 1.91 s\n",
        "-1.70287047112 4.24370615096\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test LRModel on its own\n",
      "testrange = count_vect.fit_transform(test_df['text'][:])\n",
      "pred_results = LRModel.predict(testrange.toarray())\n",
      "res = zip(test_df['useful_votes'][:].values,pred_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LRModel RMSE\n",
      "errors = []\n",
      "for r in res:\n",
      "    err = abs(r[0]-r[1])\n",
      "    errors.append(err)\n",
      "    \n",
      "print np.sqrt(np.mean([ e**2 for e in errors ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.07553284359\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = defaultdict(Counter)\n",
      "results = []\n",
      "\n",
      "for i,item in enumerate(test_df['text']):\n",
      "    label = clfr.label_new(item)\n",
      "    if label[0][1] == '1':\n",
      "        testrange = count_vect.fit_transform([item])\n",
      "        votes = LRModel.predict(testrange.toarray())\n",
      "        results.append((votes[0],test_df['useful_votes'][i]))\n",
      "        #results.append((1.5,test_df['useful_votes'][i]))\n",
      "    #elif label[0][1] == '2':\n",
      "    #    results.append((4.5,test_df['useful_votes'][i]))\n",
      "    #elif label[0][1] == '3' or label[0][1] == '2':\n",
      "    #    testrange = count_vect.fit_transform([item])\n",
      "    #    votes = LRModel.predict(testrange.toarray())\n",
      "    #    results.append((votes[0],test_df['useful_votes'][i]))\n",
      "    else:\n",
      "        results.append((0,test_df['useful_votes'][i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "[(2.4251377640089897, 0),\n",
        " (0, 0),\n",
        " (0, 1),\n",
        " (3.1405643674761361, 2),\n",
        " (4.8146035943665177, 4),\n",
        " (2.5044799068055603, 4),\n",
        " (0, 1),\n",
        " (0, 1),\n",
        " (0, 0),\n",
        " (0, 1)]"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Labeling RMSE\n",
      "errors = []\n",
      "for r in results:\n",
      "    err = abs(r[0]-r[1])\n",
      "    errors.append(err)\n",
      "\n",
      "print np.sqrt(np.mean([ e**2 for e in errors ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.52163433249\n"
       ]
      }
     ],
     "prompt_number": 75
    }
   ],
   "metadata": {}
  }
 ]
}